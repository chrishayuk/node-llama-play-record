import { CommandModule } from "yargs";
import type { LlamaGrammar } from "../../llamaEvaluator/LlamaGrammar.js";
declare const modelWrappers: readonly ["auto", "general", "llamaChat", "chatML", "falconChat"];
type ChatCommand = {
    model: string;
    systemInfo: boolean;
    systemPrompt: string;
    prompt?: string;
    wrapper: (typeof modelWrappers)[number];
    contextSize: number;
    grammar: "text" | Parameters<typeof LlamaGrammar.getFor>[0];
    jsonSchemaGrammarFile?: string;
    threads: number;
    temperature: number;
    topK: number;
    topP: number;
    gpuLayers?: number;
    repeatPenalty: number;
    lastTokensRepeatPenalty: number;
    penalizeRepeatingNewLine: boolean;
    repeatFrequencyPenalty?: number;
    repeatPresencePenalty?: number;
    maxTokens: number;
    noHistory: boolean;
};
export declare const ChatCommand: CommandModule<object, ChatCommand>;
export {};
